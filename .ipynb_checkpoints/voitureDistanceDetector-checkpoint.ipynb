{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71564494-d0ca-4f22-a0e1-f36c1e94133f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\figui/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-1-19 Python-3.9.12 torch-2.1.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from math import sqrt\n",
    "\n",
    "def centre(x1, y1, x2, y2):\n",
    "    Cx = x1 + (x2 - x1) // 2\n",
    "    Cy = y1 + (y2 - y1) // 2\n",
    "    return (Cx, Cy)\n",
    "\n",
    "def distance(x1, y1, x2, y2):\n",
    "    return sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "# Charger le modèle YOLOv5 pré-entraîné\n",
    "modele = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)  # Utiliser le CPU\n",
    "\n",
    "video = cv2.VideoCapture('videos/cars.mp4') # Vous pouvez changer la vidéo à utiliser\n",
    "\n",
    "while video.isOpened():\n",
    "    verif, cadre = video.read()\n",
    "    if not verif:\n",
    "        break\n",
    "    resultats = modele(cadre)\n",
    "    etiquettes, coordonnees = resultats.xyxyn[0][:, -1], resultats.xyxyn[0][:, :-1]\n",
    "    largeur_cadre, hauteur_cadre = cadre.shape[1], cadre.shape[0]\n",
    "    \n",
    "    for i in range(len(coordonnees)):\n",
    "        if modele.names[int(etiquettes[i])] == 'car' and coordonnees[i][4] >= 0.2:  # Si c'est une voiture\n",
    "            x1, y1 = int(coordonnees[i][0] * largeur_cadre), int(coordonnees[i][1] * hauteur_cadre)\n",
    "            x2, y2 = int(coordonnees[i][2] * largeur_cadre), int(coordonnees[i][3] * hauteur_cadre)\n",
    "            cv2.rectangle(cadre, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw rectangle around the car\n",
    "\n",
    "    centres = []\n",
    "    for i in range(len(coordonnees)):\n",
    "        if modele.names[int(etiquettes[i])] == 'car' and coordonnees[i][4] >= 0.2:  # Si c'est une voiture\n",
    "            x1, y1 = int(coordonnees[i][0] * largeur_cadre), int(coordonnees[i][1] * hauteur_cadre)\n",
    "            x2, y2 = int(coordonnees[i][2] * largeur_cadre), int(coordonnees[i][3] * hauteur_cadre)\n",
    "            cx, cy = centre(x1, y1, x2, y2)\n",
    "            centres.append((cx, cy))\n",
    "\n",
    "    for i in range(len(centres)):\n",
    "        for j in range(i + 1, len(centres)):\n",
    "            dist = distance(centres[i][0], centres[i][1], centres[j][0], centres[j][1])\n",
    "            cv2.line(cadre, centres[i], centres[j], (0, 0, 255), 1)\n",
    "            dist_m = dist / 100  # Supposons que vous voulez convertir les pixels en mètres, ajustez selon la réalité\n",
    "            cv2.putText(cadre, f\"{dist_m:.2f}m\", ((centres[i][0] + centres[j][0]) // 2, (centres[i][1] + centres[j][1]) // 2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "    \n",
    "    cv2.imshow(\"Vidéo\", cadre)\n",
    "    touche = cv2.waitKey(1)\n",
    "    if touche == 27:\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
